% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/DANN.R
\name{DANN}
\alias{DANN}
\title{This function computes the Discriminant Adaptive Nearest Neighbor (DANN)
classification algorithm.}
\usage{
DANN(Y, X, newX, K_M = NULL, K = 5, epsilon = 1)
}
\arguments{
\item{Y}{vector of non-negative integer labels corresponding to each data point.}

\item{X}{Input numeric matrix where each row is a data point whose
label is the corresponding entry in \code{Y} and each column is a
variable.}

\item{newX}{A numeric matrix where each row is a data point whose label
should be predicted using DANN classification.
If no prediction is required, \code{newX} should be set
to an empty matrix with the number of columns equal to the
number of columns of \code{X}.}

\item{K_M}{The number of neighbors to be used in learning the DANN metric
for each data point in \code{newX}.
Default value is \code{K_M = NULL}, in which case \code{K_M} will
be set to \code{K_M = max(50, floor(nrow(X)/5))} by default.}

\item{K}{The number of neighbors to be used for K-NN classification after
the DANN metric has been learned. Default value is set to
\code{K = 5}.}

\item{epsilon}{A tuning paramter which scales the DANN metric.
Default value is set to \code{epsilon = 1}.}
}
\value{
This function returns the predicted class labels of data points
        in \code{newX}. If a data point in \code{newX} violates the assumptions
        of the classifier then the data point cannot be classified and is
        assigned a label of -1.
}
\description{
This function computes the Discriminant Adaptive Nearest
             Neighbor (DANN) classification algorithm as described in [1].
             See the Vignette by using the command
             \code{browseVignette("DistanceLearning")}
             for an introduction to using DANN. Note: Normalize the data
             before usage as suggested by the authors in [1].
}
\details{
See the Vignette by using the command
         \code{browseVignette("DistanceLearning")}
         for an introduction to using DANN.
}
\examples{
# Load data from package DistanceLearning
library(DistanceLearning)
fname <- system.file("extdata", "example_data.csv", package="DistanceLearning")
df <- read.csv(fname)
Y <- as.integer(df$y)
X <- scale(as.matrix(df[,c(2,3)]))
sample_points <- sample(1:nrow(X), 40, replace = FALSE)
newX <- X[sample_points,]
subY <- Y[sample_points]

# Predict class labels for newX
Yhat <- DANN(Y[-sample_points], X[-sample_points,], newX)

# Get the accuracy
Accuracy <- length(which(Yhat == subY))/length(subY)
Accuracy

}
\references{
[1] T. Hastie, R. Tibshirani, Discriminant adaptive nearest neighbor
            classification, IEEE Transactions on Pattern Analysis and Machine
            Intelligence 18 (1996) 607-616.
}
\seealso{
\code{\link{iDANN}}
}
\author{
Carl Tony Fakhry, Ping Chen, Rahul Kulkarni and Kourosh Zarringhalam
}
